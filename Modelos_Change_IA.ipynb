{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b750e0f0",
   "metadata": {},
   "source": [
    "# Datos de Voz\n",
    "\n",
    "**Para los datos de voz usamos el DataSet de \"The Ryerson Audio-Visual Database of Emotional Speech and Song (RAVDESS )\" obtenido en la pagina \"https://www.kaggle.com/datasets/uwrfkaggler/ravdess-emotional-speech-audio\"**\n",
    "\n",
    "Con el fin de utilizarlos de una mejor manera se obtuvieron las etiquetas de las categorias de cada audio como especifica el autor.\n",
    "\n",
    "Cada uno de los 1440 archivos tiene un nombre de archivo único. El nombre del archivo consta de un identificador numérico de 7 partes (p. ej., 03-01-06-01-02-01-12.wav). Estos identificadores definen las características del estímulo:\n",
    "\n",
    "Identificadores de nombre de archivo\n",
    "\n",
    "* Modalidad (01 = full-AV, 02 = solo video, 03 = solo audio).\n",
    "* Canal vocal (01 = habla, 02 = canción).\n",
    "* Emoción (01 = neutral, 02 = tranquilo, 03 = feliz, 04 = triste, 05 = enojado, 06 = temeroso, 07 = asco, 08 = sorprendido).\n",
    "* Intensidad emocional (01 = normal, 02 = fuerte). NOTA: No hay una intensidad fuerte para la emoción 'neutral'.\n",
    "* Declaración (01 = \"Los niños hablan junto a la puerta\", 02 = \"Los perros están sentados junto a la puerta\").\n",
    "* Repetición (01 = 1ª repetición, 02 = 2ª repetición).\n",
    "* Actor (del 01 al 24. Los actores impares son hombres, los actores pares son mujeres).\n",
    "\n",
    "En el siguiente codigo vamos a almacenar los datos en un archivo Json para poder utilizar los espectrogramas sin tener que volver a cargar los audios, usamos scipy.interpolate para tener los datos del espectrograma de un mismo tamaño.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1af5930f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Actor_01', 'Actor_02', 'Actor_03', 'Actor_04', 'Actor_05', 'Actor_06', 'Actor_07', 'Actor_08', 'Actor_09', 'Actor_10', 'Actor_11', 'Actor_12', 'Actor_13', 'Actor_14', 'Actor_15', 'Actor_16', 'Actor_17', 'Actor_18', 'Actor_19', 'Actor_20', 'Actor_21', 'Actor_22', 'Actor_23', 'Actor_24']\n",
      "archive/Actor_01/\n",
      "archive/Actor_02/\n",
      "archive/Actor_03/\n",
      "archive/Actor_04/\n",
      "archive/Actor_05/\n",
      "archive/Actor_06/\n",
      "archive/Actor_07/\n",
      "archive/Actor_08/\n",
      "archive/Actor_09/\n",
      "archive/Actor_10/\n",
      "archive/Actor_11/\n",
      "archive/Actor_12/\n",
      "archive/Actor_13/\n",
      "archive/Actor_14/\n",
      "archive/Actor_15/\n",
      "archive/Actor_16/\n",
      "archive/Actor_17/\n",
      "archive/Actor_18/\n",
      "archive/Actor_19/\n",
      "archive/Actor_20/\n",
      "archive/Actor_21/\n",
      "archive/Actor_22/\n",
      "archive/Actor_23/\n",
      "archive/Actor_24/\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import librosa\n",
    "import numpy as np\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "# Establecer la ruta de la carpeta que contiene los archivos de audio\n",
    "ruta_carpeta = \"archive/\"\n",
    "print(os.listdir(ruta_carpeta)[:-1])\n",
    "# Crear una lista vacía para almacenar los datos del espectrograma de cada archivo de audio\n",
    "espectrograma = []\n",
    "max_length = 240\n",
    "\n",
    "# Recorrer cada archivo de audio en la carpeta\n",
    "for carpeta in os.listdir(ruta_carpeta)[:-1]:\n",
    "    ruta_carpeta_audio = ruta_carpeta+carpeta+\"/\"\n",
    "    print(ruta_carpeta_audio)\n",
    "    for archivo_audio in os.listdir(ruta_carpeta_audio):\n",
    "        # Comprobar que el archivo es un archivo de audio\n",
    "        if archivo_audio.endswith(\".wav\"):\n",
    "            # Obtener las etiquetas de categoría del archivo de audio a partir del nombre del archivo\n",
    "            etiquetas = archivo_audio.split(\"-\")\n",
    "            Modality = etiquetas[0]  # 01-full, 02-Video, 03-audio\n",
    "            Vocal = etiquetas[1]  # 01-speech, 02-song\n",
    "            Emotion = etiquetas[2]  # 01-neutral, 02-calm, 03-happy, 04-sad, 05-angry, 06-fearful, 07-disgust, 08-surprised\n",
    "            Intensity = etiquetas[3]  # 01-normal, 02-strong\n",
    "            Statement = etiquetas[4]  # 01-\"Kids are talking by the door\", 02-\"Dogs are sitting by the door\").\n",
    "            Repetition = etiquetas[5] # 01-1st repetition, 02-2nd repetition).\n",
    "            Actor = etiquetas[6].split(\".\")[0] # Par-Mujer, Impar-Hombre\n",
    "\n",
    "            # Cargar el archivo de audio y extraer los espectrogramas\n",
    "            ruta_archivo_audio = os.path.join(ruta_carpeta_audio, archivo_audio)\n",
    "            y, sr = librosa.load(ruta_archivo_audio,sr=22050)\n",
    "            mel_spec = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128, fmax=8000)\n",
    "            mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max)\n",
    "            f = interp1d(np.linspace(0, 1, mel_spec_db.shape[1]), mel_spec_db, kind='linear', axis=1)\n",
    "            mel_spec_db = f(np.linspace(0, 1, max_length))\n",
    "\n",
    "            # Agregar los datos del espectrograma a la lista junto con las etiquetas de categoría\n",
    "            espectrograma.append({\n",
    "                \"Modality\": Modality,\n",
    "                \"Vocal\": Vocal,\n",
    "                \"Emotion\": Emotion,\n",
    "                \"Intensity\": Intensity,\n",
    "                \"Statement\": Statement,\n",
    "                \"Repetition\": Repetition,\n",
    "                \"Actor\": Actor,\n",
    "                \"Espectrograma\": mel_spec_db.tolist()\n",
    "            })\n",
    "\n",
    "# Guardar los datos del espectrograma en un archivo JSON\n",
    "ruta_archivo_json = \"Espectrograma.json\"\n",
    "with open(ruta_archivo_json, \"w\") as archivo_json:\n",
    "    json.dump(espectrograma, archivo_json)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40adba47",
   "metadata": {},
   "source": [
    "# Carga de datos\n",
    "\n",
    "**Cargamos los datos y los guardamos en una variable llamada data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bfe3d5fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1440\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "# Crear datos de entrenamiento\n",
    "ruta_archivo_json =  \"Espectrograma.json\"\n",
    "with open(ruta_archivo_json, \"r\") as archivo_json:\n",
    "    data = json.load(archivo_json)\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d53b54b1",
   "metadata": {},
   "source": [
    "# Datos\n",
    "\n",
    "**Guardamos los datos en un DataFrame con la finalidad de poder usarlos de una manera mas facil**\n",
    "\n",
    "Tambien hacemos un acomodo aleatorio de los datos y normalizamos los datos del espectrograma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b4f6de9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Modality  Vocal  Emotion  Intensity  Statement  Repetition  Actor  \\\n",
      "0            2      0        3          0          1           0      6   \n",
      "1            2      0        2          1          0           0      6   \n",
      "2            2      0        1          0          1           0      1   \n",
      "3            2      0        7          0          0           0     17   \n",
      "4            2      0        1          0          0           1      0   \n",
      "...        ...    ...      ...        ...        ...         ...    ...   \n",
      "1435         2      0        6          0          1           1     21   \n",
      "1436         2      0        4          1          1           1     18   \n",
      "1437         2      0        1          1          1           1     20   \n",
      "1438         2      0        5          0          1           0     22   \n",
      "1439         2      0        6          0          0           0     18   \n",
      "\n",
      "                                          Espectrograma  \n",
      "0     [[-77.2802505493164, -77.09675614105608, -76.0...  \n",
      "1     [[-79.28831481933594, -74.17203339772244, -71....  \n",
      "2     [[-80.0, -80.0, -80.0, -80.0, -80.0, -80.0, -8...  \n",
      "3     [[-80.0, -80.0, -80.0, -80.0, -80.0, -80.0, -8...  \n",
      "4     [[-80.0, -79.09030259902507, -77.6292539460888...  \n",
      "...                                                 ...  \n",
      "1435  [[-80.0, -76.64583341845908, -75.5100058711223...  \n",
      "1436  [[-80.0, -80.0, -80.0, -80.0, -80.0, -79.21995...  \n",
      "1437  [[-73.65485382080078, -73.2585858141528, -70.4...  \n",
      "1438  [[-80.0, -79.58632337498365, -77.9785094640245...  \n",
      "1439  [[-58.148170471191406, -53.72611753711142, -49...  \n",
      "\n",
      "[1440 rows x 8 columns]\n",
      "0       [[-0.9317586069806869, -0.9271545380184552, -0...\n",
      "1       [[-0.9822020414728334, -0.8542531013667267, -0...\n",
      "2       [[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1...\n",
      "3       [[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1...\n",
      "4       [[-1.0, -0.9770881908124738, -0.94028994568844...\n",
      "                              ...                        \n",
      "1435    [[-1.0, -0.9153589819368464, -0.88669683960920...\n",
      "1436    [[-1.0, -1.0, -1.0, -1.0, -1.0, -0.98038769066...\n",
      "1437    [[-0.8404856144629249, -0.8305235984898851, -0...\n",
      "1438    [[-1.0, -0.9896534472773054, -0.94944007675543...\n",
      "1439    [[-0.45184241077258114, -0.3409143133066167, -...\n",
      "Name: Espectrograma, Length: 1440, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.DataFrame()\n",
    "df[\"Modality\"] = [int(data[val]['Modality'])-1 for val in range(len(data)) ]\n",
    "df[\"Vocal\"] = [int(data[val]['Vocal'])-1 for val in range(len(data)) ]\n",
    "df[\"Emotion\"] = [int(data[val]['Emotion'])-1 for val in range(len(data)) ]\n",
    "df[\"Intensity\"] = [int(data[val]['Intensity'])-1 for val in range(len(data)) ]\n",
    "df[\"Statement\"] = [int(data[val]['Statement'])-1 for val in range(len(data)) ]\n",
    "df[\"Repetition\"] = [int(data[val]['Repetition'])-1 for val in range(len(data)) ]\n",
    "df[\"Actor\"] = [int(data[val]['Actor'])-1 for val in range(len(data)) ]\n",
    "df[\"Espectrograma\"] = [np.array(data[val]['Espectrograma']) for val in range(len(data)) ]\n",
    "\n",
    "df=df.sample(frac=1).reset_index(drop=True)\n",
    "print(df)\n",
    "df_normalized = df[\"Espectrograma\"].apply(lambda x: (x - x.min()) / (x.max() - x.min()) * 2 - 1)\n",
    "print(df_normalized)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d29dc08",
   "metadata": {},
   "source": [
    "# Preparacion de datos para entrenamiento\n",
    "\n",
    "**Acomodamos los datos dejando un 20% para el test y del 80% de los datos resntante un 20% para la validacion, los datos restantes a esto seran los que usaremos para entrenar**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f3adaa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data shape:  (921, 128, 240, 1)\n",
      "train_labels shape:  (921, 1)\n",
      "val_data shape:  (231, 128, 240, 1)\n",
      "val_labels shape:  (231, 1)\n",
      "test_data shape:  (288, 128, 240, 1)\n",
      "test_labels shape:  (288, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\manue\\AppData\\Local\\Temp/ipykernel_13620/3622886832.py:15: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  train_data = train_data.astype(np.float)\n",
      "C:\\Users\\manue\\AppData\\Local\\Temp/ipykernel_13620/3622886832.py:20: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  train_labels = train_labels.astype(np.float)\n",
      "C:\\Users\\manue\\AppData\\Local\\Temp/ipykernel_13620/3622886832.py:28: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  val_data = val_data.astype(np.float)\n",
      "C:\\Users\\manue\\AppData\\Local\\Temp/ipykernel_13620/3622886832.py:32: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  val_labels = val_labels.astype(np.float)\n",
      "C:\\Users\\manue\\AppData\\Local\\Temp/ipykernel_13620/3622886832.py:41: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  test_data = test_data.astype(np.float)\n",
      "C:\\Users\\manue\\AppData\\Local\\Temp/ipykernel_13620/3622886832.py:45: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  test_labels = test_labels.astype(np.float)\n"
     ]
    }
   ],
   "source": [
    "porcentaje = 0.8\n",
    "total = len(df[\"Actor\"])\n",
    "split = porcentaje*total\n",
    "\n",
    "\n",
    "data_c = np.array([np.asarray(x) for x in df['Espectrograma'][:int(split)]])\n",
    "data_e = np.asarray(df[\"Actor\"][:int(split)])\n",
    "\n",
    "porcentaje = 0.8\n",
    "total = len(data_c)\n",
    "split2 = porcentaje*total\n",
    "\n",
    "#Train data \n",
    "train_data = data_c[:int(split2)]\n",
    "train_data = train_data.astype(np.float)\n",
    "train_data = train_data.reshape(-1, 128, 240, 1)\n",
    "\n",
    "train_labels = data_e[:int(split2)]\n",
    "train_labels = np.asarray(train_labels)\n",
    "train_labels = train_labels.astype(np.float)\n",
    "train_labels = train_labels.reshape(-1, 1)\n",
    "\n",
    "print(\"train_data shape: \",train_data.shape)\n",
    "print(\"train_labels shape: \",train_labels.shape)\n",
    "\n",
    "#Valid data\n",
    "val_data = data_c[int(split2):]\n",
    "val_data = val_data.astype(np.float)\n",
    "val_data = val_data.reshape(-1, 128, 240, 1)\n",
    "val_labels = data_e[int(split2):]\n",
    "val_labels = val_labels.astype(np.float)\n",
    "val_labels = val_labels.reshape(-1, 1)\n",
    "\n",
    "print(\"val_data shape: \",val_data.shape)\n",
    "print(\"val_labels shape: \",val_labels.shape)\n",
    "\n",
    "\n",
    "#Test data\n",
    "test_data = np.array([np.asarray(x) for x in df['Espectrograma'][int(split):]])\n",
    "test_data = test_data.astype(np.float)\n",
    "test_data = test_data.reshape(-1, 128, 240, 1)\n",
    "\n",
    "test_labels = np.asarray(df[\"Actor\"][int(split):])\n",
    "test_labels = test_labels.astype(np.float)\n",
    "test_labels = test_labels.reshape(-1, 1)\n",
    "\n",
    "print(\"test_data shape: \",test_data.shape)\n",
    "print(\"test_labels shape: \",test_labels.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f941bc",
   "metadata": {},
   "source": [
    "# Definimos la arquitectura para el modelo de Caracteristicas de Voz en personas\n",
    "\n",
    "**Para las caracteristicas de usuario usaremos la siguiente arquitectura**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc6c65e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 126, 238, 32)      320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 63, 119, 32)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 61, 117, 64)       18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 31, 59, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 117056)            0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 117056)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               14983296  \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 24)                1560      \n",
      "=================================================================\n",
      "Total params: 15,012,184\n",
      "Trainable params: 15,012,056\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Definir la arquitectura de la red neuronal\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(128, 240, 1)),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2), padding='same'),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2), padding='same'),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dropout(0.4),\n",
    "    tf.keras.layers.Dense(128, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.08)),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(64, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.04)),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(24, activation='softmax')\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4193ba8",
   "metadata": {},
   "source": [
    "# Compilación del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "68ca8c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compilar el modelo\n",
    "model.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=1e-4),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d2edd1",
   "metadata": {},
   "source": [
    "# Entrenamiento del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b6f3eea5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "12/12 [==============================] - 19s 2s/step - loss: 6.7599 - accuracy: 0.0619 - val_loss: 6.4823 - val_accuracy: 0.0519\n",
      "Epoch 2/150\n",
      "12/12 [==============================] - 20s 2s/step - loss: 6.6136 - accuracy: 0.0510 - val_loss: 6.3573 - val_accuracy: 0.0130\n",
      "Epoch 3/150\n",
      "12/12 [==============================] - 20s 2s/step - loss: 6.4445 - accuracy: 0.0521 - val_loss: 6.3031 - val_accuracy: 0.0130\n",
      "Epoch 4/150\n",
      "12/12 [==============================] - 20s 2s/step - loss: 6.2857 - accuracy: 0.0706 - val_loss: 6.2938 - val_accuracy: 0.0130\n",
      "Epoch 5/150\n",
      "12/12 [==============================] - 21s 2s/step - loss: 6.0046 - accuracy: 0.0999 - val_loss: 6.2722 - val_accuracy: 0.0303\n",
      "Epoch 6/150\n",
      "12/12 [==============================] - 21s 2s/step - loss: 5.5767 - accuracy: 0.2172 - val_loss: 6.2181 - val_accuracy: 0.0303\n",
      "Epoch 7/150\n",
      "12/12 [==============================] - 21s 2s/step - loss: 5.1606 - accuracy: 0.3018 - val_loss: 6.1603 - val_accuracy: 0.0303\n",
      "Epoch 8/150\n",
      "12/12 [==============================] - 22s 2s/step - loss: 4.8528 - accuracy: 0.4332 - val_loss: 6.1034 - val_accuracy: 0.0303\n",
      "Epoch 9/150\n",
      "12/12 [==============================] - 21s 2s/step - loss: 4.5301 - accuracy: 0.5309 - val_loss: 6.0574 - val_accuracy: 0.0303\n",
      "Epoch 10/150\n",
      "12/12 [==============================] - 21s 2s/step - loss: 4.2049 - accuracy: 0.6406 - val_loss: 6.0009 - val_accuracy: 0.0303\n",
      "Epoch 11/150\n",
      "12/12 [==============================] - 20s 2s/step - loss: 4.0725 - accuracy: 0.7036 - val_loss: 5.9506 - val_accuracy: 0.0303\n",
      "Epoch 12/150\n",
      "12/12 [==============================] - 20s 2s/step - loss: 3.8792 - accuracy: 0.7687 - val_loss: 5.8935 - val_accuracy: 0.0303\n",
      "Epoch 13/150\n",
      "12/12 [==============================] - 22s 2s/step - loss: 3.7858 - accuracy: 0.8100 - val_loss: 5.8515 - val_accuracy: 0.0303\n",
      "Epoch 14/150\n",
      "12/12 [==============================] - 23s 2s/step - loss: 3.6729 - accuracy: 0.8360 - val_loss: 5.8049 - val_accuracy: 0.0303\n",
      "Epoch 15/150\n",
      "12/12 [==============================] - 22s 2s/step - loss: 3.6072 - accuracy: 0.8306 - val_loss: 5.7604 - val_accuracy: 0.0303\n",
      "Epoch 16/150\n",
      "12/12 [==============================] - 21s 2s/step - loss: 3.5224 - accuracy: 0.8426 - val_loss: 5.7139 - val_accuracy: 0.0303\n",
      "Epoch 17/150\n",
      "12/12 [==============================] - 22s 2s/step - loss: 3.4430 - accuracy: 0.8599 - val_loss: 5.6647 - val_accuracy: 0.0303\n",
      "Epoch 18/150\n",
      "12/12 [==============================] - 23s 2s/step - loss: 3.2997 - accuracy: 0.9110 - val_loss: 5.6178 - val_accuracy: 0.0476\n",
      "Epoch 19/150\n",
      "12/12 [==============================] - 20s 2s/step - loss: 3.2251 - accuracy: 0.9131 - val_loss: 5.5878 - val_accuracy: 0.0433\n",
      "Epoch 20/150\n",
      "12/12 [==============================] - 20s 2s/step - loss: 3.1648 - accuracy: 0.9142 - val_loss: 5.5520 - val_accuracy: 0.0433\n",
      "Epoch 21/150\n",
      "12/12 [==============================] - 21s 2s/step - loss: 3.0597 - accuracy: 0.9414 - val_loss: 5.5067 - val_accuracy: 0.0433\n",
      "Epoch 22/150\n",
      "12/12 [==============================] - 21s 2s/step - loss: 3.0105 - accuracy: 0.9349 - val_loss: 5.4518 - val_accuracy: 0.0519\n",
      "Epoch 23/150\n",
      "12/12 [==============================] - 20s 2s/step - loss: 2.9227 - accuracy: 0.9511 - val_loss: 5.4108 - val_accuracy: 0.0476\n",
      "Epoch 24/150\n",
      "12/12 [==============================] - 21s 2s/step - loss: 2.8556 - accuracy: 0.9566 - val_loss: 5.3836 - val_accuracy: 0.0476\n",
      "Epoch 25/150\n",
      "12/12 [==============================] - 20s 2s/step - loss: 2.8029 - accuracy: 0.9522 - val_loss: 5.3106 - val_accuracy: 0.0779\n",
      "Epoch 26/150\n",
      "12/12 [==============================] - 22s 2s/step - loss: 2.7180 - accuracy: 0.9642 - val_loss: 5.2761 - val_accuracy: 0.0563\n",
      "Epoch 27/150\n",
      "12/12 [==============================] - 24s 2s/step - loss: 2.6598 - accuracy: 0.9696 - val_loss: 5.2374 - val_accuracy: 0.0693\n",
      "Epoch 28/150\n",
      "12/12 [==============================] - 24s 2s/step - loss: 2.6290 - accuracy: 0.9631 - val_loss: 5.1712 - val_accuracy: 0.0909\n",
      "Epoch 29/150\n",
      "12/12 [==============================] - 24s 2s/step - loss: 2.5715 - accuracy: 0.9750 - val_loss: 5.1501 - val_accuracy: 0.0649\n",
      "Epoch 30/150\n",
      "12/12 [==============================] - 23s 2s/step - loss: 2.5101 - accuracy: 0.9772 - val_loss: 5.0782 - val_accuracy: 0.1515\n",
      "Epoch 31/150\n",
      "12/12 [==============================] - 23s 2s/step - loss: 2.4522 - accuracy: 0.9685 - val_loss: 5.0588 - val_accuracy: 0.0996\n",
      "Epoch 32/150\n",
      "12/12 [==============================] - 21s 2s/step - loss: 2.4238 - accuracy: 0.9750 - val_loss: 5.0273 - val_accuracy: 0.1212\n",
      "Epoch 33/150\n",
      "12/12 [==============================] - 21s 2s/step - loss: 2.3733 - accuracy: 0.9783 - val_loss: 4.9531 - val_accuracy: 0.1645\n",
      "Epoch 34/150\n",
      "12/12 [==============================] - 21s 2s/step - loss: 2.3221 - accuracy: 0.9815 - val_loss: 4.9540 - val_accuracy: 0.1169\n",
      "Epoch 35/150\n",
      "12/12 [==============================] - 19s 2s/step - loss: 2.2695 - accuracy: 0.9815 - val_loss: 4.8712 - val_accuracy: 0.1688\n",
      "Epoch 36/150\n",
      "12/12 [==============================] - 20s 2s/step - loss: 2.2251 - accuracy: 0.9772 - val_loss: 4.8330 - val_accuracy: 0.2338\n",
      "Epoch 37/150\n",
      "12/12 [==============================] - 23s 2s/step - loss: 2.1881 - accuracy: 0.9794 - val_loss: 4.7673 - val_accuracy: 0.2641\n",
      "Epoch 38/150\n",
      "12/12 [==============================] - 23s 2s/step - loss: 2.1167 - accuracy: 0.9902 - val_loss: 4.7328 - val_accuracy: 0.2987\n",
      "Epoch 39/150\n",
      "12/12 [==============================] - 20s 2s/step - loss: 2.0707 - accuracy: 0.9870 - val_loss: 4.7037 - val_accuracy: 0.3333\n",
      "Epoch 40/150\n",
      "12/12 [==============================] - 20s 2s/step - loss: 2.0437 - accuracy: 0.9891 - val_loss: 4.6292 - val_accuracy: 0.3810\n",
      "Epoch 41/150\n",
      "12/12 [==============================] - 19s 2s/step - loss: 1.9821 - accuracy: 0.9848 - val_loss: 4.6007 - val_accuracy: 0.3723\n",
      "Epoch 42/150\n",
      "12/12 [==============================] - 19s 2s/step - loss: 1.9751 - accuracy: 0.9783 - val_loss: 4.5726 - val_accuracy: 0.3593\n",
      "Epoch 43/150\n",
      "12/12 [==============================] - 20s 2s/step - loss: 1.9154 - accuracy: 0.9891 - val_loss: 4.5081 - val_accuracy: 0.5325\n",
      "Epoch 44/150\n",
      "12/12 [==============================] - 22s 2s/step - loss: 1.8858 - accuracy: 0.9837 - val_loss: 4.5191 - val_accuracy: 0.3593\n",
      "Epoch 45/150\n",
      "12/12 [==============================] - 23s 2s/step - loss: 1.8353 - accuracy: 0.9913 - val_loss: 4.4270 - val_accuracy: 0.5584\n",
      "Epoch 46/150\n",
      "12/12 [==============================] - 23s 2s/step - loss: 1.7705 - accuracy: 0.9946 - val_loss: 4.3564 - val_accuracy: 0.6147\n",
      "Epoch 47/150\n",
      "12/12 [==============================] - 21s 2s/step - loss: 1.7551 - accuracy: 0.9902 - val_loss: 4.3273 - val_accuracy: 0.5758\n",
      "Epoch 48/150\n",
      "12/12 [==============================] - 21s 2s/step - loss: 1.7399 - accuracy: 0.9881 - val_loss: 4.2383 - val_accuracy: 0.7359\n",
      "Epoch 49/150\n",
      "12/12 [==============================] - 22s 2s/step - loss: 1.6830 - accuracy: 0.9891 - val_loss: 4.2172 - val_accuracy: 0.7143\n",
      "Epoch 50/150\n",
      "12/12 [==============================] - 23s 2s/step - loss: 1.6426 - accuracy: 0.9924 - val_loss: 4.1608 - val_accuracy: 0.7316\n",
      "Epoch 51/150\n",
      "12/12 [==============================] - 22s 2s/step - loss: 1.6101 - accuracy: 0.9902 - val_loss: 4.1426 - val_accuracy: 0.7359\n",
      "Epoch 52/150\n",
      "12/12 [==============================] - 20s 2s/step - loss: 1.5793 - accuracy: 0.9935 - val_loss: 4.0728 - val_accuracy: 0.7835\n",
      "Epoch 53/150\n",
      "12/12 [==============================] - 22s 2s/step - loss: 1.5211 - accuracy: 0.9957 - val_loss: 3.9795 - val_accuracy: 0.8398\n",
      "Epoch 54/150\n",
      "12/12 [==============================] - 21s 2s/step - loss: 1.5142 - accuracy: 0.9902 - val_loss: 4.0337 - val_accuracy: 0.6494\n",
      "Epoch 55/150\n",
      "12/12 [==============================] - 21s 2s/step - loss: 1.4862 - accuracy: 0.9902 - val_loss: 3.9375 - val_accuracy: 0.7922\n",
      "Epoch 56/150\n",
      "12/12 [==============================] - 21s 2s/step - loss: 1.4416 - accuracy: 0.9924 - val_loss: 3.9615 - val_accuracy: 0.6970\n",
      "Epoch 57/150\n",
      "12/12 [==============================] - 22s 2s/step - loss: 1.4192 - accuracy: 0.9924 - val_loss: 3.8883 - val_accuracy: 0.7879\n",
      "Epoch 58/150\n",
      "12/12 [==============================] - 22s 2s/step - loss: 1.3829 - accuracy: 0.9946 - val_loss: 3.7338 - val_accuracy: 0.8918\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/150\n",
      "12/12 [==============================] - 21s 2s/step - loss: 1.3454 - accuracy: 0.9989 - val_loss: 3.7540 - val_accuracy: 0.8225\n",
      "Epoch 60/150\n",
      "12/12 [==============================] - 21s 2s/step - loss: 1.3241 - accuracy: 0.9967 - val_loss: 3.6485 - val_accuracy: 0.8571\n",
      "Epoch 61/150\n",
      "12/12 [==============================] - 22s 2s/step - loss: 1.3076 - accuracy: 0.9902 - val_loss: 3.5646 - val_accuracy: 0.8961\n",
      "Epoch 62/150\n",
      "12/12 [==============================] - 21s 2s/step - loss: 1.2530 - accuracy: 0.9978 - val_loss: 3.6292 - val_accuracy: 0.7749\n",
      "Epoch 63/150\n",
      "12/12 [==============================] - 20s 2s/step - loss: 1.2504 - accuracy: 0.9946 - val_loss: 3.6894 - val_accuracy: 0.7706\n",
      "Epoch 64/150\n",
      "12/12 [==============================] - 21s 2s/step - loss: 1.2101 - accuracy: 0.9913 - val_loss: 3.4001 - val_accuracy: 0.9134\n",
      "Epoch 65/150\n",
      "12/12 [==============================] - 20s 2s/step - loss: 1.1634 - accuracy: 0.9967 - val_loss: 3.4543 - val_accuracy: 0.8312\n",
      "Epoch 66/150\n",
      "12/12 [==============================] - 20s 2s/step - loss: 1.1419 - accuracy: 0.9967 - val_loss: 3.3027 - val_accuracy: 0.8701\n",
      "Epoch 67/150\n",
      "12/12 [==============================] - 20s 2s/step - loss: 1.1149 - accuracy: 0.9978 - val_loss: 3.3209 - val_accuracy: 0.8268\n",
      "Epoch 68/150\n",
      "12/12 [==============================] - 21s 2s/step - loss: 1.0969 - accuracy: 0.9935 - val_loss: 3.0179 - val_accuracy: 0.9351\n",
      "Epoch 69/150\n",
      "12/12 [==============================] - 20s 2s/step - loss: 1.0634 - accuracy: 0.9989 - val_loss: 3.3493 - val_accuracy: 0.7749\n",
      "Epoch 70/150\n",
      "12/12 [==============================] - 21s 2s/step - loss: 1.0684 - accuracy: 0.9935 - val_loss: 3.1149 - val_accuracy: 0.8528\n",
      "Epoch 71/150\n",
      "12/12 [==============================] - 20s 2s/step - loss: 1.0380 - accuracy: 0.9978 - val_loss: 3.1225 - val_accuracy: 0.8571\n",
      "Epoch 72/150\n",
      "12/12 [==============================] - 20s 2s/step - loss: 0.9972 - accuracy: 0.9989 - val_loss: 3.0793 - val_accuracy: 0.8398\n",
      "Epoch 73/150\n",
      "12/12 [==============================] - 20s 2s/step - loss: 0.9729 - accuracy: 0.9967 - val_loss: 2.8897 - val_accuracy: 0.8874\n",
      "Epoch 74/150\n",
      "12/12 [==============================] - 20s 2s/step - loss: 0.9599 - accuracy: 0.9957 - val_loss: 2.6963 - val_accuracy: 0.9221\n",
      "Epoch 75/150\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.9309 - accuracy: 0.9989 - val_loss: 2.6026 - val_accuracy: 0.9307\n",
      "Epoch 76/150\n",
      "12/12 [==============================] - 23s 2s/step - loss: 0.9352 - accuracy: 0.9957 - val_loss: 2.6472 - val_accuracy: 0.9134\n",
      "Epoch 77/150\n",
      "12/12 [==============================] - 26s 2s/step - loss: 0.9169 - accuracy: 0.9924 - val_loss: 2.8436 - val_accuracy: 0.8442\n",
      "Epoch 78/150\n",
      "12/12 [==============================] - 23s 2s/step - loss: 0.8629 - accuracy: 1.0000 - val_loss: 2.5144 - val_accuracy: 0.9004\n",
      "Epoch 79/150\n",
      "12/12 [==============================] - 22s 2s/step - loss: 0.8596 - accuracy: 0.9946 - val_loss: 2.5046 - val_accuracy: 0.9004\n",
      "Epoch 80/150\n",
      "12/12 [==============================] - 22s 2s/step - loss: 0.8299 - accuracy: 0.9967 - val_loss: 2.3266 - val_accuracy: 0.9221\n",
      "Epoch 81/150\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.8146 - accuracy: 0.9978 - val_loss: 2.3632 - val_accuracy: 0.9221\n",
      "Epoch 82/150\n",
      "12/12 [==============================] - 22s 2s/step - loss: 0.8107 - accuracy: 0.9935 - val_loss: 2.2553 - val_accuracy: 0.9351\n",
      "Epoch 83/150\n",
      "12/12 [==============================] - 22s 2s/step - loss: 0.7808 - accuracy: 1.0000 - val_loss: 2.0651 - val_accuracy: 0.9307\n",
      "Epoch 84/150\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.7602 - accuracy: 0.9989 - val_loss: 2.0797 - val_accuracy: 0.9394\n",
      "Epoch 85/150\n",
      "12/12 [==============================] - 20s 2s/step - loss: 0.7484 - accuracy: 0.9978 - val_loss: 2.0667 - val_accuracy: 0.9177\n",
      "Epoch 86/150\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.7276 - accuracy: 1.0000 - val_loss: 2.0706 - val_accuracy: 0.8831\n",
      "Epoch 87/150\n",
      "12/12 [==============================] - 20s 2s/step - loss: 0.7071 - accuracy: 0.9989 - val_loss: 1.7158 - val_accuracy: 0.9394\n",
      "Epoch 88/150\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.6992 - accuracy: 0.9978 - val_loss: 1.7320 - val_accuracy: 0.9394\n",
      "Epoch 89/150\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.6811 - accuracy: 0.9957 - val_loss: 1.6718 - val_accuracy: 0.9394\n",
      "Epoch 90/150\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.6724 - accuracy: 0.9967 - val_loss: 1.8655 - val_accuracy: 0.8658\n",
      "Epoch 91/150\n",
      "12/12 [==============================] - 22s 2s/step - loss: 0.6651 - accuracy: 0.9935 - val_loss: 1.5238 - val_accuracy: 0.9524\n",
      "Epoch 92/150\n",
      "12/12 [==============================] - 20s 2s/step - loss: 0.6453 - accuracy: 1.0000 - val_loss: 1.5009 - val_accuracy: 0.9437\n",
      "Epoch 93/150\n",
      "12/12 [==============================] - 20s 2s/step - loss: 0.6332 - accuracy: 0.9946 - val_loss: 1.3993 - val_accuracy: 0.9437\n",
      "Epoch 94/150\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.6052 - accuracy: 1.0000 - val_loss: 1.4948 - val_accuracy: 0.9048\n",
      "Epoch 95/150\n",
      "12/12 [==============================] - 24s 2s/step - loss: 0.5963 - accuracy: 1.0000 - val_loss: 1.2349 - val_accuracy: 0.9524\n",
      "Epoch 96/150\n",
      "12/12 [==============================] - 23s 2s/step - loss: 0.5689 - accuracy: 1.0000 - val_loss: 1.2975 - val_accuracy: 0.9437\n",
      "Epoch 97/150\n",
      "12/12 [==============================] - 22s 2s/step - loss: 0.5770 - accuracy: 0.9978 - val_loss: 1.2885 - val_accuracy: 0.9307\n",
      "Epoch 98/150\n",
      "12/12 [==============================] - 20s 2s/step - loss: 0.5671 - accuracy: 0.9967 - val_loss: 1.1613 - val_accuracy: 0.9437\n",
      "Epoch 99/150\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.5482 - accuracy: 0.9978 - val_loss: 1.3327 - val_accuracy: 0.9134\n",
      "Epoch 100/150\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.5294 - accuracy: 1.0000 - val_loss: 1.0715 - val_accuracy: 0.9524\n",
      "Epoch 101/150\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.5342 - accuracy: 0.9957 - val_loss: 1.0840 - val_accuracy: 0.9437\n",
      "Epoch 102/150\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.5084 - accuracy: 0.9978 - val_loss: 1.1840 - val_accuracy: 0.8788\n",
      "Epoch 103/150\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.5117 - accuracy: 0.9967 - val_loss: 1.0571 - val_accuracy: 0.9524\n",
      "Epoch 104/150\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.4918 - accuracy: 0.9978 - val_loss: 0.9857 - val_accuracy: 0.9610\n",
      "Epoch 105/150\n",
      "12/12 [==============================] - 22s 2s/step - loss: 0.4894 - accuracy: 0.9978 - val_loss: 0.9388 - val_accuracy: 0.9654\n",
      "Epoch 106/150\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.4768 - accuracy: 0.9967 - val_loss: 1.0926 - val_accuracy: 0.9221\n",
      "Epoch 107/150\n",
      "12/12 [==============================] - 22s 2s/step - loss: 0.4667 - accuracy: 0.9978 - val_loss: 0.9836 - val_accuracy: 0.9437\n",
      "Epoch 108/150\n",
      "12/12 [==============================] - 20s 2s/step - loss: 0.4621 - accuracy: 0.9967 - val_loss: 0.8236 - val_accuracy: 0.9524\n",
      "Epoch 109/150\n",
      "12/12 [==============================] - 22s 2s/step - loss: 0.4491 - accuracy: 0.9957 - val_loss: 0.8317 - val_accuracy: 0.9351\n",
      "Epoch 110/150\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.4307 - accuracy: 0.9978 - val_loss: 0.8322 - val_accuracy: 0.9264\n",
      "Epoch 111/150\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.4150 - accuracy: 0.9978 - val_loss: 0.7431 - val_accuracy: 0.9307\n",
      "Epoch 112/150\n",
      "12/12 [==============================] - 20s 2s/step - loss: 0.4215 - accuracy: 0.9989 - val_loss: 0.8852 - val_accuracy: 0.9307\n",
      "Epoch 113/150\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.4116 - accuracy: 0.9989 - val_loss: 0.8960 - val_accuracy: 0.9394\n",
      "Epoch 114/150\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.3974 - accuracy: 0.9989 - val_loss: 0.6543 - val_accuracy: 0.9610\n",
      "Epoch 115/150\n",
      "12/12 [==============================] - 23s 2s/step - loss: 0.3950 - accuracy: 1.0000 - val_loss: 0.7403 - val_accuracy: 0.9437\n",
      "Epoch 116/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 22s 2s/step - loss: 0.3958 - accuracy: 0.9967 - val_loss: 0.6394 - val_accuracy: 0.9481\n",
      "Epoch 117/150\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.3783 - accuracy: 0.9967 - val_loss: 0.8440 - val_accuracy: 0.9048\n",
      "Epoch 118/150\n",
      "12/12 [==============================] - 22s 2s/step - loss: 0.3834 - accuracy: 0.9989 - val_loss: 0.7789 - val_accuracy: 0.9351\n",
      "Epoch 119/150\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.3800 - accuracy: 0.9978 - val_loss: 0.7375 - val_accuracy: 0.9264\n",
      "Epoch 120/150\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.3620 - accuracy: 0.9989 - val_loss: 0.6612 - val_accuracy: 0.9524\n",
      "Epoch 121/150\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.3649 - accuracy: 0.9967 - val_loss: 0.7450 - val_accuracy: 0.9264\n",
      "Epoch 122/150\n",
      "12/12 [==============================] - 22s 2s/step - loss: 0.3589 - accuracy: 0.9946 - val_loss: 0.8030 - val_accuracy: 0.9221\n",
      "Epoch 123/150\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.3531 - accuracy: 0.9967 - val_loss: 0.5807 - val_accuracy: 0.9481\n",
      "Epoch 124/150\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.3359 - accuracy: 0.9989 - val_loss: 0.6118 - val_accuracy: 0.9481\n",
      "Epoch 125/150\n",
      "12/12 [==============================] - 22s 2s/step - loss: 0.3328 - accuracy: 0.9967 - val_loss: 0.5593 - val_accuracy: 0.9524\n",
      "Epoch 126/150\n",
      "12/12 [==============================] - 22s 2s/step - loss: 0.3321 - accuracy: 0.9978 - val_loss: 0.7084 - val_accuracy: 0.9221\n",
      "Epoch 127/150\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.3245 - accuracy: 0.9989 - val_loss: 0.5631 - val_accuracy: 0.9437\n",
      "Epoch 128/150\n",
      "12/12 [==============================] - 22s 2s/step - loss: 0.3324 - accuracy: 0.9935 - val_loss: 0.5832 - val_accuracy: 0.9697\n",
      "Epoch 129/150\n",
      "12/12 [==============================] - 22s 2s/step - loss: 0.3113 - accuracy: 0.9967 - val_loss: 0.5329 - val_accuracy: 0.9567\n",
      "Epoch 130/150\n",
      "12/12 [==============================] - 19s 2s/step - loss: 0.3093 - accuracy: 0.9989 - val_loss: 0.5245 - val_accuracy: 0.9524\n",
      "Epoch 131/150\n",
      "12/12 [==============================] - 19s 2s/step - loss: 0.3141 - accuracy: 0.9978 - val_loss: 0.6598 - val_accuracy: 0.9394\n",
      "Epoch 132/150\n",
      "12/12 [==============================] - 19s 2s/step - loss: 0.3128 - accuracy: 0.9935 - val_loss: 0.5791 - val_accuracy: 0.9307\n",
      "Epoch 133/150\n",
      "12/12 [==============================] - 19s 2s/step - loss: 0.2919 - accuracy: 0.9989 - val_loss: 0.6072 - val_accuracy: 0.9177\n",
      "Epoch 134/150\n",
      "12/12 [==============================] - 20s 2s/step - loss: 0.2896 - accuracy: 0.9978 - val_loss: 0.6170 - val_accuracy: 0.9264\n",
      "Epoch 135/150\n",
      "12/12 [==============================] - 20s 2s/step - loss: 0.2895 - accuracy: 0.9967 - val_loss: 0.4838 - val_accuracy: 0.9481\n",
      "Epoch 136/150\n",
      "12/12 [==============================] - 19s 2s/step - loss: 0.2811 - accuracy: 1.0000 - val_loss: 0.5844 - val_accuracy: 0.9134\n",
      "Epoch 137/150\n",
      "12/12 [==============================] - 20s 2s/step - loss: 0.2880 - accuracy: 0.9978 - val_loss: 0.7456 - val_accuracy: 0.8745\n",
      "Epoch 138/150\n",
      "12/12 [==============================] - 20s 2s/step - loss: 0.2729 - accuracy: 1.0000 - val_loss: 0.5132 - val_accuracy: 0.9394\n",
      "Epoch 139/150\n",
      "12/12 [==============================] - 20s 2s/step - loss: 0.2730 - accuracy: 0.9978 - val_loss: 0.5464 - val_accuracy: 0.9481\n",
      "Epoch 140/150\n",
      "12/12 [==============================] - 20s 2s/step - loss: 0.2740 - accuracy: 0.9946 - val_loss: 0.7060 - val_accuracy: 0.8961\n",
      "Epoch 141/150\n",
      "12/12 [==============================] - 19s 2s/step - loss: 0.2572 - accuracy: 0.9989 - val_loss: 0.4859 - val_accuracy: 0.9481\n",
      "Epoch 142/150\n",
      "12/12 [==============================] - 19s 2s/step - loss: 0.2613 - accuracy: 0.9989 - val_loss: 0.4646 - val_accuracy: 0.9524\n",
      "Epoch 143/150\n",
      "12/12 [==============================] - 19s 2s/step - loss: 0.2649 - accuracy: 0.9935 - val_loss: 0.4557 - val_accuracy: 0.9481\n",
      "Epoch 144/150\n",
      "12/12 [==============================] - 19s 2s/step - loss: 0.2684 - accuracy: 0.9957 - val_loss: 0.4937 - val_accuracy: 0.9481\n",
      "Epoch 145/150\n",
      "12/12 [==============================] - 19s 2s/step - loss: 0.2474 - accuracy: 1.0000 - val_loss: 0.4723 - val_accuracy: 0.9654\n",
      "Epoch 146/150\n",
      "12/12 [==============================] - 19s 2s/step - loss: 0.2507 - accuracy: 0.9967 - val_loss: 0.4513 - val_accuracy: 0.9351\n",
      "Epoch 147/150\n",
      "12/12 [==============================] - 19s 2s/step - loss: 0.2482 - accuracy: 0.9989 - val_loss: 0.4994 - val_accuracy: 0.9394\n",
      "Epoch 148/150\n",
      "12/12 [==============================] - 19s 2s/step - loss: 0.2465 - accuracy: 0.9967 - val_loss: 0.5054 - val_accuracy: 0.9481\n",
      "Epoch 149/150\n",
      "12/12 [==============================] - 19s 2s/step - loss: 0.2592 - accuracy: 0.9946 - val_loss: 0.4944 - val_accuracy: 0.9481\n",
      "Epoch 150/150\n",
      "12/12 [==============================] - 19s 2s/step - loss: 0.2403 - accuracy: 0.9978 - val_loss: 0.4365 - val_accuracy: 0.9437\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1eb28ddbdc0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Entrenar el modelo\n",
    "\n",
    "model.fit(train_data, \n",
    "          train_labels, \n",
    "          epochs=150, \n",
    "          steps_per_epoch = 12,\n",
    "          validation_steps = 3,\n",
    "          validation_data=(val_data, val_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b664e01",
   "metadata": {},
   "source": [
    "# Evaluación del Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1152026c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 1s 134ms/step - loss: 0.6719 - accuracy: 0.9062\n",
      "Test accuracy: 0.90625\n"
     ]
    }
   ],
   "source": [
    "# Evaluar el modelo en el conjunto de prueba\n",
    "test_loss, test_acc = model.evaluate(test_data, test_labels)\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b29fad7",
   "metadata": {},
   "source": [
    "# Guardamos el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5dd405b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('Personas.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6e20f4b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([16], dtype=int64),) 0.9944478 [16.]\n",
      "[16]\n"
     ]
    }
   ],
   "source": [
    "num = 51\n",
    "array = model.predict(test_data)[num]\n",
    "print(np.where(array == max(array)), max(array),test_labels[num])\n",
    "print(np.where(array == max(array))[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e67fe25",
   "metadata": {},
   "source": [
    "# Datos para el modelo de Detección de Sentimientos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2d26b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "porcentaje = 0.8\n",
    "total = len(df[\"Emotion\"])\n",
    "split = porcentaje*total\n",
    "\n",
    "\n",
    "data_c = np.array([np.asarray(x) for x in df['Espectrograma'][:int(split)]])\n",
    "data_e = np.asarray(df[\"Emotion\"][:int(split)])\n",
    "\n",
    "porcentaje = 0.8\n",
    "total = len(data_c)\n",
    "split2 = porcentaje*total\n",
    "\n",
    "#Train data \n",
    "train_data = data_c[:int(split2)]\n",
    "train_data = train_data.astype(np.float)\n",
    "train_data = train_data.reshape(-1, 128, 240, 1)\n",
    "\n",
    "train_labels = data_e[:int(split2)]\n",
    "train_labels = np.asarray(train_labels)\n",
    "train_labels = train_labels.astype(np.float)\n",
    "train_labels = train_labels.reshape(-1, 1)\n",
    "\n",
    "print(\"train_data shape: \",train_data.shape)\n",
    "print(\"train_labels shape: \",train_labels.shape)\n",
    "\n",
    "#Valid data\n",
    "val_data = data_c[int(split2):]\n",
    "val_data = val_data.astype(np.float)\n",
    "val_data = val_data.reshape(-1, 128, 240, 1)\n",
    "\n",
    "val_labels = data_e[int(split2):]\n",
    "val_labels = val_labels.astype(np.float)\n",
    "val_labels = val_labels.reshape(-1, 1)\n",
    "\n",
    "print(\"val_data shape: \",val_data.shape)\n",
    "print(\"val_labels shape: \",val_labels.shape)\n",
    "\n",
    "\n",
    "#Test data\n",
    "test_data = np.array([np.asarray(x) for x in df['Espectrograma'][int(split):]])\n",
    "test_data = test_data.astype(np.float)\n",
    "test_data = test_data.reshape(-1, 128, 240, 1)\n",
    "\n",
    "test_labels = np.asarray(df[\"Emotion\"][int(split):])\n",
    "test_labels = test_labels.astype(np.float)\n",
    "test_labels = test_labels.reshape(-1, 1)\n",
    "\n",
    "print(\"test_data shape: \",test_data.shape)\n",
    "print(\"test_labels shape: \",test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ab257a",
   "metadata": {},
   "source": [
    "# Definimos la arquitectura para el modelo de Caracteristicas de emociones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b52921f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Definir la arquitectura de la red neuronal\n",
    "model_2 = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(128, 240, 1)),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2), padding='same'),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2), padding='same'),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dropout(0.4),\n",
    "    tf.keras.layers.Dense(64, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.05)),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(32, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.02)),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(8, activation='softmax')\n",
    "])\n",
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f1a1f35",
   "metadata": {},
   "source": [
    "# Compilamos el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c763f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compilar el modelo\n",
    "model_2.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=1e-4),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a69ab47b",
   "metadata": {},
   "source": [
    "# Entrenamiento del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1196ba96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenar el modelo\n",
    "\n",
    "model_2.fit(train_data, \n",
    "          train_labels, \n",
    "          epochs=150, \n",
    "          steps_per_epoch = 12,\n",
    "          validation_steps = 3,\n",
    "          validation_data=(val_data, val_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af53486",
   "metadata": {},
   "source": [
    "# Evaluacion de Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26879d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluar el modelo en el conjunto de prueba\n",
    "test_loss, test_acc = model_2.evaluate(test_data, test_labels)\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c03e93f",
   "metadata": {},
   "source": [
    "# Guardamos el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e839bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('emociones_Spec.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
